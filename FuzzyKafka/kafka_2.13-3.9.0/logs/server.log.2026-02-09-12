[2026-02-09 12:00:29,383] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: Removing member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-8354e21c-dc98-46a4-89a2-94ffd54109d9 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:00:29,713] INFO [GroupCoordinator 1]: Group predictive-maintenance-engine with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:00:29,849] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-8354e21c-dc98-46a4-89a2-94ffd54109d9, groupInstanceId=None, clientId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group predictive-maintenance-engine through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:01:40,788] INFO Sent auto-creation request for Set(urgent-alerts) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-02-09 12:01:41,408] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(urgent-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:01:41,475] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-38342 in Empty state. Created a new member id console-consumer-e9928fec-b1e0-4ae4-9538-99fa93d02e2b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:01:41,503] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-38342 in state PreparingRebalance with old generation 0 (__consumer_offsets-41) (reason: Adding new member console-consumer-e9928fec-b1e0-4ae4-9538-99fa93d02e2b with group instance id None; client reason: need to re-join with the given member-id: console-consumer-e9928fec-b1e0-4ae4-9538-99fa93d02e2b) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:01:41,504] INFO [LogLoader partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:01:41,527] INFO Created log for partition urgent-alerts-0 in /tmp/kraft-combined-logs/urgent-alerts-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:01:41,537] INFO [Partition urgent-alerts-0 broker=1] No checkpointed highwatermark is found for partition urgent-alerts-0 (kafka.cluster.Partition)
[2026-02-09 12:01:41,538] INFO [Partition urgent-alerts-0 broker=1] Log loaded for partition urgent-alerts-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:01:44,508] INFO [GroupCoordinator 1]: Stabilized group console-consumer-38342 generation 1 (__consumer_offsets-41) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:01:44,578] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-e9928fec-b1e0-4ae4-9538-99fa93d02e2b for group console-consumer-38342 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:02:48,684] INFO [NodeToControllerChannelManager id=1 name=registration] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-02-09 12:02:58,444] INFO [GroupMetadataManager brokerId=1] Group predictive-maintenance-engine transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-02-09 12:04:19,085] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-38342 in state PreparingRebalance with old generation 1 (__consumer_offsets-41) (reason: Removing member console-consumer-e9928fec-b1e0-4ae4-9538-99fa93d02e2b on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:04:19,094] INFO [GroupCoordinator 1]: Group console-consumer-38342 with generation 2 is now empty (__consumer_offsets-41) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:04:19,116] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=console-consumer-e9928fec-b1e0-4ae4-9538-99fa93d02e2b, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-38342 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:02,356] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group predictive-maintenance-engine in Empty state. Created a new member id predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-72f1d72b-a0c8-4fed-a75b-376cbee9ff2c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:02,397] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-72f1d72b-a0c8-4fed-a75b-376cbee9ff2c with group instance id None; client reason: need to re-join with the given member-id: predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-72f1d72b-a0c8-4fed-a75b-376cbee9ff2c) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:05,399] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 1 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:05,862] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-72f1d72b-a0c8-4fed-a75b-376cbee9ff2c for group predictive-maintenance-engine for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:09,368] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: Removing member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-72f1d72b-a0c8-4fed-a75b-376cbee9ff2c on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:09,385] INFO [GroupCoordinator 1]: Group predictive-maintenance-engine with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:09,405] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-72f1d72b-a0c8-4fed-a75b-376cbee9ff2c, groupInstanceId=None, clientId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group predictive-maintenance-engine through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:43,162] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-95703 in Empty state. Created a new member id console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:43,206] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-95703 in state PreparingRebalance with old generation 0 (__consumer_offsets-15) (reason: Adding new member console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 with group instance id None; client reason: need to re-join with the given member-id: console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:46,211] INFO [GroupCoordinator 1]: Stabilized group console-consumer-95703 generation 1 (__consumer_offsets-15) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:05:46,303] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 for group console-consumer-95703 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:06:43,220] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-64606 in Empty state. Created a new member id console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:06:43,236] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-64606 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc with group instance id None; client reason: need to re-join with the given member-id: console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:06:46,244] INFO [GroupCoordinator 1]: Stabilized group console-consumer-64606 generation 1 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:06:46,342] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc for group console-consumer-64606 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:00,683] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0, urgent-alerts-0, fuzzy-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:10:00,699] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0, urgent-alerts-0, fuzzy-alerts-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:10:00,772] INFO Sent auto-creation request for Set(fuzzy-alerts) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-02-09 12:10:00,842] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-64606 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: Leader console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:00,848] INFO [GroupCoordinator 1]: Stabilized group console-consumer-64606 generation 2 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:00,884] INFO Sent auto-creation request for Set(urgent-alerts) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-02-09 12:10:00,896] INFO Sent auto-creation request for Set(fuzzy-alerts) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-02-09 12:10:00,901] INFO Log for partition fuzzy-alerts-0 is renamed to /tmp/kraft-combined-logs/fuzzy-alerts-0.1332a4a0c5dc4c6da6e07e1c5c17979b-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:10:00,918] INFO Log for partition industrial-raw-data-0 is renamed to /tmp/kraft-combined-logs/industrial-raw-data-0.64c1e7ff403e4d1eab9ad76e25259590-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:10:00,927] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc for group console-consumer-64606 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:00,937] INFO Log for partition urgent-alerts-0 is renamed to /tmp/kraft-combined-logs/urgent-alerts-0.e5e894670b4a45b2b2291ce478052db9-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:10:00,976] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-95703 in state PreparingRebalance with old generation 1 (__consumer_offsets-15) (reason: Leader console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:00,984] INFO [GroupCoordinator 1]: Stabilized group console-consumer-95703 generation 2 (__consumer_offsets-15) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:01,007] INFO Sent auto-creation request for Set(urgent-alerts) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-02-09 12:10:01,020] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 for group console-consumer-95703 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:01,034] INFO [GroupMetadataManager brokerId=1] Group console-consumer-38342 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-02-09 12:10:01,063] INFO [GroupMetadataManager brokerId=1] Group predictive-maintenance-engine transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-02-09 12:10:01,070] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: industrial-raw-data-0, fuzzy-alerts-0, urgent-alerts-0. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:01,070] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:10:01,085] INFO [LogLoader partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:10:01,087] INFO Created log for partition fuzzy-alerts-0 in /tmp/kraft-combined-logs/fuzzy-alerts-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:10:01,099] INFO [Partition fuzzy-alerts-0 broker=1] Log loaded for partition fuzzy-alerts-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:10:01,127] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-64606 in state PreparingRebalance with old generation 2 (__consumer_offsets-3) (reason: Leader console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:01,135] INFO [GroupCoordinator 1]: Stabilized group console-consumer-64606 generation 3 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:01,142] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(urgent-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:10:01,150] INFO [LogLoader partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:10:01,153] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc for group console-consumer-64606 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:01,155] INFO Created log for partition urgent-alerts-0 in /tmp/kraft-combined-logs/urgent-alerts-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:10:01,176] INFO [Partition urgent-alerts-0 broker=1] Log loaded for partition urgent-alerts-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:10:01,249] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-95703 in state PreparingRebalance with old generation 2 (__consumer_offsets-15) (reason: Leader console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:01,251] INFO [GroupCoordinator 1]: Stabilized group console-consumer-95703 generation 3 (__consumer_offsets-15) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:01,262] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 for group console-consumer-95703 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:36,654] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:10:36,707] INFO [LogLoader partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:10:36,718] INFO Created log for partition industrial-raw-data-0 in /tmp/kraft-combined-logs/industrial-raw-data-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:10:36,732] INFO [Partition industrial-raw-data-0 broker=1] No checkpointed highwatermark is found for partition industrial-raw-data-0 (kafka.cluster.Partition)
[2026-02-09 12:10:36,735] INFO [Partition industrial-raw-data-0 broker=1] Log loaded for partition industrial-raw-data-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:10:40,238] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group predictive-maintenance-engine in Empty state. Created a new member id predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-4e54ddff-ed7f-4595-a3cf-93fd1c827114 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:40,256] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-4e54ddff-ed7f-4595-a3cf-93fd1c827114 with group instance id None; client reason: need to re-join with the given member-id: predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-4e54ddff-ed7f-4595-a3cf-93fd1c827114) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:43,261] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 1 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:10:43,959] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-4e54ddff-ed7f-4595-a3cf-93fd1c827114 for group predictive-maintenance-engine for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:11:00,981] INFO [LocalLog partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=206, lastModifiedTime=1770635109140, largestRecordTimestamp=1770634826271) (kafka.log.LocalLog)
[2026-02-09 12:11:01,020] INFO [LocalLog partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=206, lastModifiedTime=1770635109140, largestRecordTimestamp=1770634826271) (kafka.log.LocalLog$)
[2026-02-09 12:11:01,088] INFO Deleted log /tmp/kraft-combined-logs/fuzzy-alerts-0.1332a4a0c5dc4c6da6e07e1c5c17979b-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:11:01,211] INFO Deleted offset index /tmp/kraft-combined-logs/fuzzy-alerts-0.1332a4a0c5dc4c6da6e07e1c5c17979b-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:11:01,215] INFO Deleted time index /tmp/kraft-combined-logs/fuzzy-alerts-0.1332a4a0c5dc4c6da6e07e1c5c17979b-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:11:01,337] INFO Deleted log for partition fuzzy-alerts-0 in /tmp/kraft-combined-logs/fuzzy-alerts-0.1332a4a0c5dc4c6da6e07e1c5c17979b-delete. (kafka.log.LogManager)
[2026-02-09 12:11:01,344] INFO [LocalLog partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=35364, lastModifiedTime=1770635248229, largestRecordTimestamp=1770635248224) (kafka.log.LocalLog)
[2026-02-09 12:11:01,356] INFO [LocalLog partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=35364, lastModifiedTime=1770635248229, largestRecordTimestamp=1770635248224) (kafka.log.LocalLog$)
[2026-02-09 12:11:01,356] INFO Deleted log /tmp/kraft-combined-logs/industrial-raw-data-0.64c1e7ff403e4d1eab9ad76e25259590-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:11:01,359] INFO Deleted offset index /tmp/kraft-combined-logs/industrial-raw-data-0.64c1e7ff403e4d1eab9ad76e25259590-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:11:01,367] INFO Deleted time index /tmp/kraft-combined-logs/industrial-raw-data-0.64c1e7ff403e4d1eab9ad76e25259590-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:11:01,379] INFO Deleted log for partition industrial-raw-data-0 in /tmp/kraft-combined-logs/industrial-raw-data-0.64c1e7ff403e4d1eab9ad76e25259590-delete. (kafka.log.LogManager)
[2026-02-09 12:11:01,390] INFO [LocalLog partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1770634901484, largestRecordTimestamp=-1) (kafka.log.LocalLog)
[2026-02-09 12:11:01,479] INFO [LocalLog partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1770634901484, largestRecordTimestamp=-1) (kafka.log.LocalLog$)
[2026-02-09 12:11:01,486] INFO Deleted log /tmp/kraft-combined-logs/urgent-alerts-0.e5e894670b4a45b2b2291ce478052db9-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:11:01,487] INFO Deleted offset index /tmp/kraft-combined-logs/urgent-alerts-0.e5e894670b4a45b2b2291ce478052db9-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:11:01,536] INFO Deleted time index /tmp/kraft-combined-logs/urgent-alerts-0.e5e894670b4a45b2b2291ce478052db9-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:11:01,537] INFO Deleted log for partition urgent-alerts-0 in /tmp/kraft-combined-logs/urgent-alerts-0.e5e894670b4a45b2b2291ce478052db9-delete. (kafka.log.LogManager)
[2026-02-09 12:12:02,616] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group predictive-maintenance-engine in Stable state. Created a new member id predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-faf5d2ea-d1e7-458f-9e01-e3792dfef8d0 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:02,643] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: Adding new member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-faf5d2ea-d1e7-458f-9e01-e3792dfef8d0 with group instance id None; client reason: need to re-join with the given member-id: predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-faf5d2ea-d1e7-458f-9e01-e3792dfef8d0) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:04,700] INFO [GroupCoordinator 1]: Member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-4e54ddff-ed7f-4595-a3cf-93fd1c827114 in group predictive-maintenance-engine has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:04,701] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 2 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:05,007] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-faf5d2ea-d1e7-458f-9e01-e3792dfef8d0 for group predictive-maintenance-engine for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:58,721] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:12:58,723] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:12:58,756] INFO Log for partition industrial-raw-data-0 is renamed to /tmp/kraft-combined-logs/industrial-raw-data-0.0ade1dc4313747c8a6ac8e16675b91a3-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:12:58,838] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 2 (__consumer_offsets-18) (reason: Leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-faf5d2ea-d1e7-458f-9e01-e3792dfef8d0 re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:58,838] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 3 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:58,864] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: industrial-raw-data-0. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:58,906] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-faf5d2ea-d1e7-458f-9e01-e3792dfef8d0 for group predictive-maintenance-engine for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:59,030] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 3 (__consumer_offsets-18) (reason: Removing member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-faf5d2ea-d1e7-458f-9e01-e3792dfef8d0 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:59,034] INFO [GroupCoordinator 1]: Group predictive-maintenance-engine with generation 4 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:12:59,037] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-faf5d2ea-d1e7-458f-9e01-e3792dfef8d0, groupInstanceId=None, clientId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group predictive-maintenance-engine through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:17,150] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:13:17,195] INFO [LogLoader partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:13:17,210] INFO Created log for partition industrial-raw-data-0 in /tmp/kraft-combined-logs/industrial-raw-data-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:13:17,211] INFO [Partition industrial-raw-data-0 broker=1] No checkpointed highwatermark is found for partition industrial-raw-data-0 (kafka.cluster.Partition)
[2026-02-09 12:13:17,212] INFO [Partition industrial-raw-data-0 broker=1] Log loaded for partition industrial-raw-data-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:13:19,755] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group predictive-maintenance-engine in Empty state. Created a new member id predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-715d46fc-9fcb-4b5c-a2d2-d82434d39231 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:19,761] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 4 (__consumer_offsets-18) (reason: Adding new member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-715d46fc-9fcb-4b5c-a2d2-d82434d39231 with group instance id None; client reason: need to re-join with the given member-id: predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-715d46fc-9fcb-4b5c-a2d2-d82434d39231) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:22,765] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 5 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:23,003] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-715d46fc-9fcb-4b5c-a2d2-d82434d39231 for group predictive-maintenance-engine for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:42,628] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:13:42,628] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:13:42,651] INFO Log for partition industrial-raw-data-0 is renamed to /tmp/kraft-combined-logs/industrial-raw-data-0.5ed8e7cee20943f7a5c306314ecd3500-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:13:42,720] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 5 (__consumer_offsets-18) (reason: Leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-715d46fc-9fcb-4b5c-a2d2-d82434d39231 re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:42,721] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 6 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:42,746] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: industrial-raw-data-0. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:42,793] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-715d46fc-9fcb-4b5c-a2d2-d82434d39231 for group predictive-maintenance-engine for generation 6. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:42,958] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 6 (__consumer_offsets-18) (reason: Removing member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-715d46fc-9fcb-4b5c-a2d2-d82434d39231 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:42,959] INFO [GroupCoordinator 1]: Group predictive-maintenance-engine with generation 7 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:42,960] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-715d46fc-9fcb-4b5c-a2d2-d82434d39231, groupInstanceId=None, clientId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group predictive-maintenance-engine through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:57,420] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:13:57,420] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:13:57,452] INFO Log for partition fuzzy-alerts-0 is renamed to /tmp/kraft-combined-logs/fuzzy-alerts-0.c7c86308d49f4b6f847e3d816eb66046-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:13:57,473] INFO Sent auto-creation request for Set(fuzzy-alerts) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-02-09 12:13:57,562] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-64606 in state PreparingRebalance with old generation 3 (__consumer_offsets-3) (reason: Leader console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:57,565] INFO [GroupCoordinator 1]: Stabilized group console-consumer-64606 generation 4 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:57,583] INFO [GroupMetadataManager brokerId=1] Group predictive-maintenance-engine transitioned to Dead in generation 7 (kafka.coordinator.group.GroupMetadataManager)
[2026-02-09 12:13:57,585] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: fuzzy-alerts-0. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:57,593] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:13:57,612] INFO [LogLoader partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:13:57,628] INFO Created log for partition fuzzy-alerts-0 in /tmp/kraft-combined-logs/fuzzy-alerts-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:13:57,629] INFO [Partition fuzzy-alerts-0 broker=1] Log loaded for partition fuzzy-alerts-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:13:57,666] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc for group console-consumer-64606 for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:13:58,759] INFO [LocalLog partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635436701, largestRecordTimestamp=-1) (kafka.log.LocalLog)
[2026-02-09 12:13:58,759] INFO [LocalLog partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635436701, largestRecordTimestamp=-1) (kafka.log.LocalLog$)
[2026-02-09 12:13:58,761] INFO Deleted log /tmp/kraft-combined-logs/industrial-raw-data-0.0ade1dc4313747c8a6ac8e16675b91a3-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:13:58,761] INFO Deleted offset index /tmp/kraft-combined-logs/industrial-raw-data-0.0ade1dc4313747c8a6ac8e16675b91a3-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:13:58,762] INFO Deleted time index /tmp/kraft-combined-logs/industrial-raw-data-0.0ade1dc4313747c8a6ac8e16675b91a3-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:13:58,763] INFO Deleted log for partition industrial-raw-data-0 in /tmp/kraft-combined-logs/industrial-raw-data-0.0ade1dc4313747c8a6ac8e16675b91a3-delete. (kafka.log.LogManager)
[2026-02-09 12:14:14,705] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(urgent-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:14:14,706] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(urgent-alerts-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:14:14,749] INFO Log for partition urgent-alerts-0 is renamed to /tmp/kraft-combined-logs/urgent-alerts-0.553c4c45dff14e668555257f76d5b9d8-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:14:14,751] INFO Sent auto-creation request for Set(urgent-alerts) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-02-09 12:14:14,777] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-95703 in state PreparingRebalance with old generation 3 (__consumer_offsets-15) (reason: Leader console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:14:14,778] INFO [GroupCoordinator 1]: Stabilized group console-consumer-95703 generation 4 (__consumer_offsets-15) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:14:14,849] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: urgent-alerts-0. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:14:14,849] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(urgent-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:14:14,853] INFO [LogLoader partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:14:14,866] INFO Created log for partition urgent-alerts-0 in /tmp/kraft-combined-logs/urgent-alerts-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:14:14,874] INFO [Partition urgent-alerts-0 broker=1] Log loaded for partition urgent-alerts-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:14:14,891] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 for group console-consumer-95703 for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:14:28,656] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:14:28,722] INFO [LogLoader partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:14:28,748] INFO Created log for partition industrial-raw-data-0 in /tmp/kraft-combined-logs/industrial-raw-data-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:14:28,750] INFO [Partition industrial-raw-data-0 broker=1] No checkpointed highwatermark is found for partition industrial-raw-data-0 (kafka.cluster.Partition)
[2026-02-09 12:14:28,767] INFO [Partition industrial-raw-data-0 broker=1] Log loaded for partition industrial-raw-data-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:14:31,326] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group predictive-maintenance-engine in Empty state. Created a new member id predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-cdb879f6-418f-49e8-a66b-e3db797bada4 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:14:31,364] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-cdb879f6-418f-49e8-a66b-e3db797bada4 with group instance id None; client reason: need to re-join with the given member-id: predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-cdb879f6-418f-49e8-a66b-e3db797bada4) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:14:34,365] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 1 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:14:34,618] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-cdb879f6-418f-49e8-a66b-e3db797bada4 for group predictive-maintenance-engine for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:14:42,655] INFO [LocalLog partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635597185, largestRecordTimestamp=-1) (kafka.log.LocalLog)
[2026-02-09 12:14:42,656] INFO [LocalLog partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635597185, largestRecordTimestamp=-1) (kafka.log.LocalLog$)
[2026-02-09 12:14:42,656] INFO Deleted log /tmp/kraft-combined-logs/industrial-raw-data-0.5ed8e7cee20943f7a5c306314ecd3500-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:14:42,662] INFO Deleted offset index /tmp/kraft-combined-logs/industrial-raw-data-0.5ed8e7cee20943f7a5c306314ecd3500-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:14:42,663] INFO Deleted time index /tmp/kraft-combined-logs/industrial-raw-data-0.5ed8e7cee20943f7a5c306314ecd3500-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:14:42,664] INFO Deleted log for partition industrial-raw-data-0 in /tmp/kraft-combined-logs/industrial-raw-data-0.5ed8e7cee20943f7a5c306314ecd3500-delete. (kafka.log.LogManager)
[2026-02-09 12:14:57,453] INFO [LocalLog partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635401082, largestRecordTimestamp=-1) (kafka.log.LocalLog)
[2026-02-09 12:14:57,453] INFO [LocalLog partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635401082, largestRecordTimestamp=-1) (kafka.log.LocalLog$)
[2026-02-09 12:14:57,454] INFO Deleted log /tmp/kraft-combined-logs/fuzzy-alerts-0.c7c86308d49f4b6f847e3d816eb66046-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:14:57,454] INFO Deleted offset index /tmp/kraft-combined-logs/fuzzy-alerts-0.c7c86308d49f4b6f847e3d816eb66046-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:14:57,454] INFO Deleted time index /tmp/kraft-combined-logs/fuzzy-alerts-0.c7c86308d49f4b6f847e3d816eb66046-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:14:57,455] INFO Deleted log for partition fuzzy-alerts-0 in /tmp/kraft-combined-logs/fuzzy-alerts-0.c7c86308d49f4b6f847e3d816eb66046-delete. (kafka.log.LogManager)
[2026-02-09 12:15:14,751] INFO [LocalLog partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635401148, largestRecordTimestamp=-1) (kafka.log.LocalLog)
[2026-02-09 12:15:14,756] INFO [LocalLog partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635401148, largestRecordTimestamp=-1) (kafka.log.LocalLog$)
[2026-02-09 12:15:14,757] INFO Deleted log /tmp/kraft-combined-logs/urgent-alerts-0.553c4c45dff14e668555257f76d5b9d8-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:15:14,759] INFO Deleted offset index /tmp/kraft-combined-logs/urgent-alerts-0.553c4c45dff14e668555257f76d5b9d8-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:15:14,761] INFO Deleted time index /tmp/kraft-combined-logs/urgent-alerts-0.553c4c45dff14e668555257f76d5b9d8-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:15:14,795] INFO Deleted log for partition urgent-alerts-0 in /tmp/kraft-combined-logs/urgent-alerts-0.553c4c45dff14e668555257f76d5b9d8-delete. (kafka.log.LogManager)
[2026-02-09 12:16:14,703] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-64606 in state PreparingRebalance with old generation 4 (__consumer_offsets-3) (reason: Removing member console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:14,705] INFO [GroupCoordinator 1]: Group console-consumer-64606 with generation 5 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:14,707] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=console-consumer-8687eb4f-d7dd-42f3-84d4-84e2994a8fcc, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-64606 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:41,599] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-95703 in state PreparingRebalance with old generation 4 (__consumer_offsets-15) (reason: Removing member console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5 on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:41,605] INFO [GroupCoordinator 1]: Group console-consumer-95703 with generation 5 is now empty (__consumer_offsets-15) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:41,607] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=console-consumer-b15ce564-d38c-4f99-8e2f-7134dc3e30c5, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-95703 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:53,543] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:16:53,546] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:16:53,579] INFO Log for partition industrial-raw-data-0 is renamed to /tmp/kraft-combined-logs/industrial-raw-data-0.dbeab07f71304dca9c22b12df9845927-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:16:53,692] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: Leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-cdb879f6-418f-49e8-a66b-e3db797bada4 re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:53,702] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 2 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:53,726] INFO [GroupMetadataManager brokerId=1] Group console-consumer-64606 transitioned to Dead in generation 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-02-09 12:16:53,727] INFO [GroupMetadataManager brokerId=1] Group console-consumer-95703 transitioned to Dead in generation 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-02-09 12:16:53,728] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: industrial-raw-data-0. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:53,738] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-cdb879f6-418f-49e8-a66b-e3db797bada4 for group predictive-maintenance-engine for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:53,895] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 2 (__consumer_offsets-18) (reason: Removing member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-cdb879f6-418f-49e8-a66b-e3db797bada4 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:53,896] INFO [GroupCoordinator 1]: Group predictive-maintenance-engine with generation 3 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:16:53,908] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-cdb879f6-418f-49e8-a66b-e3db797bada4, groupInstanceId=None, clientId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group predictive-maintenance-engine through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:17:03,253] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(urgent-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:17:03,254] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(urgent-alerts-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:17:03,286] INFO Log for partition urgent-alerts-0 is renamed to /tmp/kraft-combined-logs/urgent-alerts-0.e9a675b4c6f54e43afd5e4aba90e594e-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:17:03,370] INFO [GroupMetadataManager brokerId=1] Group predictive-maintenance-engine transitioned to Dead in generation 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-02-09 12:17:03,371] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: urgent-alerts-0. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:17:11,488] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:17:11,494] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:17:11,526] INFO Log for partition fuzzy-alerts-0 is renamed to /tmp/kraft-combined-logs/fuzzy-alerts-0.224e55c3a42d41bdac5f7439fe4b752d-delete and is scheduled for deletion (kafka.log.LogManager)
[2026-02-09 12:17:11,633] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: fuzzy-alerts-0. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:17:34,240] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(industrial-raw-data-0, fuzzy-alerts-0, urgent-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:17:34,255] INFO [LogLoader partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:17:34,292] INFO Created log for partition industrial-raw-data-0 in /tmp/kraft-combined-logs/industrial-raw-data-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:17:34,295] INFO [Partition industrial-raw-data-0 broker=1] No checkpointed highwatermark is found for partition industrial-raw-data-0 (kafka.cluster.Partition)
[2026-02-09 12:17:34,295] INFO [Partition industrial-raw-data-0 broker=1] Log loaded for partition industrial-raw-data-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:17:34,352] INFO [LogLoader partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:17:34,362] INFO Created log for partition fuzzy-alerts-0 in /tmp/kraft-combined-logs/fuzzy-alerts-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:17:34,362] INFO [Partition fuzzy-alerts-0 broker=1] No checkpointed highwatermark is found for partition fuzzy-alerts-0 (kafka.cluster.Partition)
[2026-02-09 12:17:34,363] INFO [Partition fuzzy-alerts-0 broker=1] Log loaded for partition fuzzy-alerts-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:17:34,429] INFO [LogLoader partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:17:34,432] INFO Created log for partition urgent-alerts-0 in /tmp/kraft-combined-logs/urgent-alerts-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:17:34,434] INFO [Partition urgent-alerts-0 broker=1] No checkpointed highwatermark is found for partition urgent-alerts-0 (kafka.cluster.Partition)
[2026-02-09 12:17:34,447] INFO [Partition urgent-alerts-0 broker=1] Log loaded for partition urgent-alerts-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:17:36,614] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group predictive-maintenance-engine in Empty state. Created a new member id predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-b24d02e1-b91e-4f8a-8028-accf3212c1c3 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:17:36,640] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-b24d02e1-b91e-4f8a-8028-accf3212c1c3 with group instance id None; client reason: need to re-join with the given member-id: predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-b24d02e1-b91e-4f8a-8028-accf3212c1c3) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:17:39,644] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 1 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:17:40,671] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-b24d02e1-b91e-4f8a-8028-accf3212c1c3 for group predictive-maintenance-engine for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:17:53,660] INFO [LocalLog partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635668696, largestRecordTimestamp=-1) (kafka.log.LocalLog)
[2026-02-09 12:17:53,716] INFO [LocalLog partition=industrial-raw-data-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635668696, largestRecordTimestamp=-1) (kafka.log.LocalLog$)
[2026-02-09 12:17:53,716] INFO Deleted log /tmp/kraft-combined-logs/industrial-raw-data-0.dbeab07f71304dca9c22b12df9845927-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:17:53,717] INFO Deleted offset index /tmp/kraft-combined-logs/industrial-raw-data-0.dbeab07f71304dca9c22b12df9845927-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:17:53,717] INFO Deleted time index /tmp/kraft-combined-logs/industrial-raw-data-0.dbeab07f71304dca9c22b12df9845927-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:17:53,718] INFO Deleted log for partition industrial-raw-data-0 in /tmp/kraft-combined-logs/industrial-raw-data-0.dbeab07f71304dca9c22b12df9845927-delete. (kafka.log.LogManager)
[2026-02-09 12:18:03,286] INFO [LocalLog partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635654847, largestRecordTimestamp=-1) (kafka.log.LocalLog)
[2026-02-09 12:18:03,288] INFO [LocalLog partition=urgent-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635654847, largestRecordTimestamp=-1) (kafka.log.LocalLog$)
[2026-02-09 12:18:03,290] INFO Deleted log /tmp/kraft-combined-logs/urgent-alerts-0.e9a675b4c6f54e43afd5e4aba90e594e-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:18:03,290] INFO Deleted offset index /tmp/kraft-combined-logs/urgent-alerts-0.e9a675b4c6f54e43afd5e4aba90e594e-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:18:03,291] INFO Deleted time index /tmp/kraft-combined-logs/urgent-alerts-0.e9a675b4c6f54e43afd5e4aba90e594e-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:18:03,294] INFO Deleted log for partition urgent-alerts-0 in /tmp/kraft-combined-logs/urgent-alerts-0.e9a675b4c6f54e43afd5e4aba90e594e-delete. (kafka.log.LogManager)
[2026-02-09 12:18:11,533] INFO [LocalLog partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635637598, largestRecordTimestamp=-1) (kafka.log.LocalLog)
[2026-02-09 12:18:11,534] INFO [LocalLog partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1770635637598, largestRecordTimestamp=-1) (kafka.log.LocalLog$)
[2026-02-09 12:18:11,559] INFO Deleted log /tmp/kraft-combined-logs/fuzzy-alerts-0.224e55c3a42d41bdac5f7439fe4b752d-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:18:11,560] INFO Deleted offset index /tmp/kraft-combined-logs/fuzzy-alerts-0.224e55c3a42d41bdac5f7439fe4b752d-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:18:11,561] INFO Deleted time index /tmp/kraft-combined-logs/fuzzy-alerts-0.224e55c3a42d41bdac5f7439fe4b752d-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2026-02-09 12:18:11,562] INFO Deleted log for partition fuzzy-alerts-0 in /tmp/kraft-combined-logs/fuzzy-alerts-0.224e55c3a42d41bdac5f7439fe4b752d-delete. (kafka.log.LogManager)
[2026-02-09 12:19:46,862] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-91234 in Empty state. Created a new member id console-consumer-2ad0d606-5b20-4030-b25e-6c822b3b5fd6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:19:46,878] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-91234 in state PreparingRebalance with old generation 0 (__consumer_offsets-40) (reason: Adding new member console-consumer-2ad0d606-5b20-4030-b25e-6c822b3b5fd6 with group instance id None; client reason: need to re-join with the given member-id: console-consumer-2ad0d606-5b20-4030-b25e-6c822b3b5fd6) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:19:49,888] INFO [GroupCoordinator 1]: Stabilized group console-consumer-91234 generation 1 (__consumer_offsets-40) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:19:50,017] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-2ad0d606-5b20-4030-b25e-6c822b3b5fd6 for group console-consumer-91234 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:20:26,180] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-54924 in Empty state. Created a new member id console-consumer-d38ca2e8-9f70-4b9f-954b-f27e50ab887a and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:20:26,203] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-54924 in state PreparingRebalance with old generation 0 (__consumer_offsets-25) (reason: Adding new member console-consumer-d38ca2e8-9f70-4b9f-954b-f27e50ab887a with group instance id None; client reason: need to re-join with the given member-id: console-consumer-d38ca2e8-9f70-4b9f-954b-f27e50ab887a) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:20:29,206] INFO [GroupCoordinator 1]: Stabilized group console-consumer-54924 generation 1 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:20:29,284] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-d38ca2e8-9f70-4b9f-954b-f27e50ab887a for group console-consumer-54924 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:20:44,660] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: Removing member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-b24d02e1-b91e-4f8a-8028-accf3212c1c3 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:20:44,662] INFO [GroupCoordinator 1]: Group predictive-maintenance-engine with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:20:44,673] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-b24d02e1-b91e-4f8a-8028-accf3212c1c3, groupInstanceId=None, clientId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group predictive-maintenance-engine through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:22:58,367] INFO [GroupMetadataManager brokerId=1] Group predictive-maintenance-engine transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-02-09 12:26:47,252] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group predictive-maintenance-engine in Empty state. Created a new member id predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-64b4384e-82b0-46f1-a26a-86fcd07bd82d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:26:47,321] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-64b4384e-82b0-46f1-a26a-86fcd07bd82d with group instance id None; client reason: need to re-join with the given member-id: predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-64b4384e-82b0-46f1-a26a-86fcd07bd82d) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:26:50,324] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 1 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:26:50,663] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-64b4384e-82b0-46f1-a26a-86fcd07bd82d for group predictive-maintenance-engine for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:26:55,675] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: Removing member predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-64b4384e-82b0-46f1-a26a-86fcd07bd82d on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:26:55,680] INFO [GroupCoordinator 1]: Group predictive-maintenance-engine with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:26:55,682] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer-64b4384e-82b0-46f1-a26a-86fcd07bd82d, groupInstanceId=None, clientId=predictive-maintenance-engine-9a8ad1f0-a264-4341-a493-7b17e9d67221-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group predictive-maintenance-engine through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:29:12,055] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group predictive-maintenance-engine in Empty state. Created a new member id predictive-maintenance-engine-e07f859c-c781-45a4-a1b3-778f398615ba-StreamThread-1-consumer-ac9e2b2b-21d7-4083-92ae-2278a520ccb8 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:29:12,114] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 2 (__consumer_offsets-18) (reason: Adding new member predictive-maintenance-engine-e07f859c-c781-45a4-a1b3-778f398615ba-StreamThread-1-consumer-ac9e2b2b-21d7-4083-92ae-2278a520ccb8 with group instance id None; client reason: need to re-join with the given member-id: predictive-maintenance-engine-e07f859c-c781-45a4-a1b3-778f398615ba-StreamThread-1-consumer-ac9e2b2b-21d7-4083-92ae-2278a520ccb8) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:29:15,116] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 3 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:29:15,412] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-e07f859c-c781-45a4-a1b3-778f398615ba-StreamThread-1-consumer-ac9e2b2b-21d7-4083-92ae-2278a520ccb8 for group predictive-maintenance-engine for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:29:18,833] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 3 (__consumer_offsets-18) (reason: Removing member predictive-maintenance-engine-e07f859c-c781-45a4-a1b3-778f398615ba-StreamThread-1-consumer-ac9e2b2b-21d7-4083-92ae-2278a520ccb8 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:29:18,833] INFO [GroupCoordinator 1]: Group predictive-maintenance-engine with generation 4 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:29:18,834] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=predictive-maintenance-engine-e07f859c-c781-45a4-a1b3-778f398615ba-StreamThread-1-consumer-ac9e2b2b-21d7-4083-92ae-2278a520ccb8, groupInstanceId=None, clientId=predictive-maintenance-engine-e07f859c-c781-45a4-a1b3-778f398615ba-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group predictive-maintenance-engine through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:30:54,943] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group predictive-maintenance-engine in Empty state. Created a new member id predictive-maintenance-engine-63522aa1-d467-449a-8a60-0ed0aa8b0cb6-StreamThread-1-consumer-9f466884-3bba-446b-8dea-89d1d9182047 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:30:54,960] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 4 (__consumer_offsets-18) (reason: Adding new member predictive-maintenance-engine-63522aa1-d467-449a-8a60-0ed0aa8b0cb6-StreamThread-1-consumer-9f466884-3bba-446b-8dea-89d1d9182047 with group instance id None; client reason: need to re-join with the given member-id: predictive-maintenance-engine-63522aa1-d467-449a-8a60-0ed0aa8b0cb6-StreamThread-1-consumer-9f466884-3bba-446b-8dea-89d1d9182047) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:30:57,962] INFO [GroupCoordinator 1]: Stabilized group predictive-maintenance-engine generation 5 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:30:58,173] INFO [GroupCoordinator 1]: Assignment received from leader predictive-maintenance-engine-63522aa1-d467-449a-8a60-0ed0aa8b0cb6-StreamThread-1-consumer-9f466884-3bba-446b-8dea-89d1d9182047 for group predictive-maintenance-engine for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:32:43,368] INFO [GroupCoordinator 1]: Member predictive-maintenance-engine-63522aa1-d467-449a-8a60-0ed0aa8b0cb6-StreamThread-1-consumer-9f466884-3bba-446b-8dea-89d1d9182047 in group predictive-maintenance-engine has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:32:43,370] INFO [GroupCoordinator 1]: Preparing to rebalance group predictive-maintenance-engine in state PreparingRebalance with old generation 5 (__consumer_offsets-18) (reason: removing member predictive-maintenance-engine-63522aa1-d467-449a-8a60-0ed0aa8b0cb6-StreamThread-1-consumer-9f466884-3bba-446b-8dea-89d1d9182047 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:32:43,372] INFO [GroupCoordinator 1]: Group predictive-maintenance-engine with generation 6 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:32:57,201] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-54924 in state PreparingRebalance with old generation 1 (__consumer_offsets-25) (reason: Removing member console-consumer-d38ca2e8-9f70-4b9f-954b-f27e50ab887a on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:32:57,205] INFO [GroupCoordinator 1]: Group console-consumer-54924 with generation 2 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:32:57,210] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=console-consumer-d38ca2e8-9f70-4b9f-954b-f27e50ab887a, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-54924 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:32:58,370] INFO [GroupMetadataManager brokerId=1] Group console-consumer-54924 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-02-09 12:38:43,755] ERROR Error while writing to checkpoint file /tmp/kraft-combined-logs/replication-offset-checkpoint (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.io.FileNotFoundException: /tmp/kraft-combined-logs/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:293)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:235)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:184)
	at org.apache.kafka.server.common.CheckpointFile.write(CheckpointFile.java:78)
	at org.apache.kafka.storage.internals.checkpoint.CheckpointFileWithFailureHandler.write(CheckpointFileWithFailureHandler.java:53)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:71)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7(ReplicaManager.scala:2447)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7$adapted(ReplicaManager.scala:2447)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:2447)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:2446)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:905)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:2446)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:360)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:151)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2026-02-09 12:38:44,089] WARN [ReplicaManager broker=1] Stopping serving replicas in dir /tmp/kraft-combined-logs with uuid Some(8tqgZgDB9OWJ6BzliMNO5w) because the log directory has failed. (kafka.server.ReplicaManager)
[2026-02-09 12:38:44,090] ERROR [ReplicaManager broker=1] Error while writing to highwatermark file in directory /tmp/kraft-combined-logs (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /tmp/kraft-combined-logs/replication-offset-checkpoint
Caused by: java.io.FileNotFoundException: /tmp/kraft-combined-logs/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:293)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:235)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:184)
	at org.apache.kafka.server.common.CheckpointFile.write(CheckpointFile.java:78)
	at org.apache.kafka.storage.internals.checkpoint.CheckpointFileWithFailureHandler.write(CheckpointFileWithFailureHandler.java:53)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:71)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7(ReplicaManager.scala:2447)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7$adapted(ReplicaManager.scala:2447)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:2447)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:2446)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:905)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:2446)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:360)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:151)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2026-02-09 12:38:44,260] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, urgent-alerts-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, industrial-raw-data-0, fuzzy-alerts-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, urgents-alerts-0, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, predictive-maintenance-engine-counts-store-changelog-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:38:44,264] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, urgent-alerts-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, industrial-raw-data-0, fuzzy-alerts-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, urgents-alerts-0, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, predictive-maintenance-engine-counts-store-changelog-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:38:44,551] WARN [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,urgent-alerts-0,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-37,__consumer_offsets-38,industrial-raw-data-0,fuzzy-alerts-0,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,urgents-alerts-0,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,predictive-maintenance-engine-counts-store-changelog-0,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory /tmp/kraft-combined-logs. (kafka.server.ReplicaManager)
[2026-02-09 12:38:44,586] WARN Stopping serving logs in dir /tmp/kraft-combined-logs (kafka.log.LogManager)
[2026-02-09 12:38:44,768] ERROR Shutdown broker because all log dirs in /tmp/kraft-combined-logs have failed (kafka.log.LogManager)
[2026-02-09 12:39:14,347] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2026-02-09 12:39:15,321] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2026-02-09 12:39:16,247] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2026-02-09 12:39:16,274] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
[2026-02-09 12:39:18,094] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-02-09 12:39:18,287] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2026-02-09 12:39:18,376] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-02-09 12:39:18,387] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
[2026-02-09 12:39:18,745] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:39:18,753] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-02-09 12:39:18,756] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-02-09 12:39:18,986] INFO Initialized snapshots with IDs SortedSet() from /tmp/kraft-combined-logs/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2026-02-09 12:39:19,050] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-02-09 12:39:19,160] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:39:19,187] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=Optional.empty), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/127.0.0.1:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:39:19,190] INFO [RaftManager id=1] Starting request manager with static voters: [localhost:9093 (id: 1 rack: null)] (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:39:19,215] INFO [RaftManager id=1] Attempting durable transition to Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1636, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:39:19,845] INFO [RaftManager id=1] Completed transition to Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1636, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:39:19,856] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=QkT2CihmXoTtm5OmU4hotQ,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@53ac845a}, highWatermark=Optional.empty, electionTimeoutMs=1213) from Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1636, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:39:19,891] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=QkT2CihmXoTtm5OmU4hotQ,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@53ac845a}, highWatermark=Optional.empty, electionTimeoutMs=1213) from Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1636, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:39:19,921] INFO [RaftManager id=1] Attempting durable transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=Optional[QkT2CihmXoTtm5OmU4hotQ]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=QkT2CihmXoTtm5OmU4hotQ,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@53ac845a}, highWatermark=Optional.empty, electionTimeoutMs=1213) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:39:19,970] INFO [RaftManager id=1] Completed transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=Optional[QkT2CihmXoTtm5OmU4hotQ]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=QkT2CihmXoTtm5OmU4hotQ,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@53ac845a}, highWatermark=Optional.empty, electionTimeoutMs=1213) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:39:20,116] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-02-09 12:39:20,132] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:39:20,273] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
[2026-02-09 12:39:20,309] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,324] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2026-02-09 12:39:20,330] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2026-02-09 12:39:20,372] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1047047668 (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:39:20,386] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@1047047668 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:39:20,399] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,421] INFO [MetadataLoader id=1] initializeNewPublishers: The loader finished catching up to the current high water mark of 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,529] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@61441133 (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:39:20,530] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 0 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,537] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@61441133 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:39:20,586] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:20,587] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:20,606] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:20,608] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:20,749] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:20,904] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,904] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,905] INFO [ControllerServer id=1] Loaded new metadata Features(metadataVersion=3.9-IV0, finalizedFeatures={metadata.version=21}, finalizedFeaturesEpoch=4). (org.apache.kafka.metadata.publisher.FeaturesPublisher)
[2026-02-09 12:39:20,905] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,905] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,906] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,910] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:20,954] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2026-02-09 12:39:20,969] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2026-02-09 12:39:20,995] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2026-02-09 12:39:20,990] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:21,005] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:21,074] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
[2026-02-09 12:39:21,084] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:21,115] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:21,179] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:21,180] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:21,184] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2026-02-09 12:39:21,186] INFO [ControllerRegistrationManager id=1 incarnation=bP2_u43oQaSwfUoh50O18Q] initialized channel manager. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:39:21,191] INFO [ControllerRegistrationManager id=1 incarnation=bP2_u43oQaSwfUoh50O18Q] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=bP2_u43oQaSwfUoh50O18Q, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='localhost', port=9093, securityProtocol=0)], features=[Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)]) (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:39:21,197] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2026-02-09 12:39:21,199] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2026-02-09 12:39:21,200] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2026-02-09 12:39:21,203] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2026-02-09 12:39:21,213] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
[2026-02-09 12:39:21,312] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:21,315] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:21,351] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:21,422] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:21,701] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-02-09 12:39:21,704] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-02-09 12:39:21,749] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:21,753] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:21,878] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-02-09 12:39:22,078] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-02-09 12:39:22,115] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2026-02-09 12:39:22,216] INFO [ControllerRegistrationManager id=1 incarnation=bP2_u43oQaSwfUoh50O18Q] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:39:22,236] INFO [ControllerRegistrationManager id=1 incarnation=bP2_u43oQaSwfUoh50O18Q] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:39:22,239] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:22,239] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:22,321] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:22,321] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:22,402] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:22,414] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:22,432] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:22,436] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:22,446] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:22,556] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:22,578] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:22,688] INFO Unable to read the broker epoch in /tmp/kraft-combined-logs. (kafka.log.LogManager)
[2026-02-09 12:39:22,703] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:22,705] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:22,726] INFO [BrokerLifecycleManager id=1] Incarnation 0Rxbd2x5SHmyRyYvAcZzaA of broker 1 in cluster 5paNe1NBRn-fbOhng8ompQ is now STARTING. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:39:22,893] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:22,995] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 10 (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:39:23,104] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:39:23,148] INFO [BrokerLifecycleManager id=1] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:39:23,176] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-02-09 12:39:23,178] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-02-09 12:39:23,178] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 10 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:23,183] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 10 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:23,187] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-02-09 12:39:23,187] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-02-09 12:39:23,187] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-02-09 12:39:23,189] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=10, epoch=1) with metadata.version 3.9-IV0. (kafka.server.metadata.BrokerMetadataPublisher)
[2026-02-09 12:39:23,197] INFO Loading logs from log dirs ArrayBuffer(/tmp/kraft-combined-logs) (kafka.log.LogManager)
[2026-02-09 12:39:23,224] INFO No logs found to be loaded in /tmp/kraft-combined-logs (kafka.log.LogManager)
[2026-02-09 12:39:23,237] INFO Loaded 0 logs in 38ms (kafka.log.LogManager)
[2026-02-09 12:39:23,243] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2026-02-09 12:39:23,245] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2026-02-09 12:39:24,604] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2026-02-09 12:39:24,761] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-02-09 12:39:24,780] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2026-02-09 12:39:24,803] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:39:24,836] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:39:24,842] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:39:24,868] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-02-09 12:39:24,875] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:39:24,954] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 10 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:39:24,960] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-02-09 12:39:24,966] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://localhost:9092,CONTROLLER://localhost:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092,CONTROLLER://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /tmp/kraft-combined-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2026-02-09 12:39:24,995] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-02-09 12:39:25,093] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:39:25,098] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-02-09 12:39:25,100] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-02-09 12:39:25,101] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2026-02-09 12:39:25,102] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2026-02-09 12:39:25,124] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-02-09 12:39:25,138] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-02-09 12:39:25,141] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-02-09 12:39:25,142] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-02-09 12:39:25,142] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2026-02-09 12:39:25,144] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:39:25,146] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:39:25,146] INFO Kafka startTimeMs: 1770637165142 (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:39:25,154] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
[2026-02-09 12:39:25,569] INFO Sent auto-creation request for Set(fuzzy-alerts) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-02-09 12:39:25,872] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:39:26,077] INFO [LogLoader partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:39:26,181] INFO Created log for partition fuzzy-alerts-0 in /tmp/kraft-combined-logs/fuzzy-alerts-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:39:26,239] INFO [Partition fuzzy-alerts-0 broker=1] No checkpointed highwatermark is found for partition fuzzy-alerts-0 (kafka.cluster.Partition)
[2026-02-09 12:39:26,297] INFO [Partition fuzzy-alerts-0 broker=1] Log loaded for partition fuzzy-alerts-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:39:51,692] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2026-02-09 12:39:51,714] INFO [BrokerServer id=1] Transition from STARTED to SHUTTING_DOWN (kafka.server.BrokerServer)
[2026-02-09 12:39:51,727] INFO [BrokerServer id=1] shutting down (kafka.server.BrokerServer)
[2026-02-09 12:39:51,766] INFO [BrokerLifecycleManager id=1] Beginning controlled shutdown. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:39:51,940] INFO [BrokerLifecycleManager id=1] The broker is in PENDING_CONTROLLED_SHUTDOWN state, still waiting for the active controller. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:39:52,038] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:39:52,040] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:39:52,103] INFO [BrokerLifecycleManager id=1] The controller has asked us to exit controlled shutdown. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:39:52,104] INFO [BrokerLifecycleManager id=1] beginShutdown: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:52,112] INFO [BrokerLifecycleManager id=1] Transitioning from PENDING_CONTROLLED_SHUTDOWN to SHUTTING_DOWN. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:39:52,119] INFO [broker-1-to-controller-heartbeat-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,124] INFO [broker-1-to-controller-heartbeat-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,125] INFO [broker-1-to-controller-heartbeat-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,139] INFO [SocketServer listenerType=BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2026-02-09 12:39:52,263] INFO Node to controller channel manager for heartbeat shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:39:52,309] INFO [SocketServer listenerType=BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2026-02-09 12:39:52,339] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2026-02-09 12:39:52,367] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2026-02-09 12:39:52,376] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,378] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,380] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,388] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2026-02-09 12:39:52,497] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:39:52,512] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2026-02-09 12:39:52,519] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-02-09 12:39:52,531] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-02-09 12:39:52,534] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-02-09 12:39:52,575] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:39:52,597] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:39:52,647] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,655] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,655] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,660] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,660] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,662] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,664] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:39:52,671] INFO [AssignmentsManager id=1]KafkaEventQueue#close: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:52,673] INFO [AssignmentsManager id=1] shutting down. (org.apache.kafka.server.AssignmentsManager)
[2026-02-09 12:39:52,674] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,674] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,674] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,676] INFO Node to controller channel manager for directory-assignments shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:39:52,679] INFO [AssignmentsManager id=1]closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:52,681] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2026-02-09 12:39:52,688] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-02-09 12:39:52,688] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-02-09 12:39:52,688] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-02-09 12:39:52,689] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:39:52,691] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:39:52,695] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:39:52,709] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:39:52,709] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,709] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,720] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,728] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,735] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,735] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,736] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,789] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,790] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,791] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,802] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,803] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,803] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,805] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,805] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:52,866] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2026-02-09 12:39:52,866] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2026-02-09 12:39:52,867] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2026-02-09 12:39:52,883] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2026-02-09 12:39:52,898] INFO [broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,903] INFO [broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,905] INFO [broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,908] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:39:52,914] INFO [broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,919] INFO [broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,921] INFO [broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:52,944] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:39:52,951] INFO Shutting down. (kafka.log.LogManager)
[2026-02-09 12:39:52,974] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2026-02-09 12:39:52,986] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2026-02-09 12:39:52,989] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2026-02-09 12:39:53,440] INFO Shutdown complete. (kafka.log.LogManager)
[2026-02-09 12:39:53,450] INFO [broker-1-ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,467] INFO [broker-1-ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,469] INFO [broker-1-ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,470] INFO [broker-1-ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,485] INFO [broker-1-ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,486] INFO [broker-1-ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,488] INFO [broker-1-ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,490] INFO [broker-1-ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,491] INFO [broker-1-ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,492] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,493] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,493] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:53,498] INFO [SocketServer listenerType=BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2026-02-09 12:39:53,660] INFO [SocketServer listenerType=BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2026-02-09 12:39:53,669] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2026-02-09 12:39:53,684] INFO [BrokerLifecycleManager id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:53,686] INFO [client-metrics-reaper]: Shutting down (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-02-09 12:39:53,712] INFO [client-metrics-reaper]: Stopped (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-02-09 12:39:53,713] INFO [client-metrics-reaper]: Shutdown completed (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-02-09 12:39:53,739] INFO [BrokerServer id=1] shut down completed (kafka.server.BrokerServer)
[2026-02-09 12:39:53,744] INFO [BrokerServer id=1] Transition from SHUTTING_DOWN to SHUTDOWN (kafka.server.BrokerServer)
[2026-02-09 12:39:53,749] INFO [ControllerServer id=1] shutting down (kafka.server.ControllerServer)
[2026-02-09 12:39:53,757] INFO [raft-expiration-reaper]: Shutting down (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-02-09 12:39:53,861] INFO [raft-expiration-reaper]: Stopped (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-02-09 12:39:53,863] INFO [raft-expiration-reaper]: Shutdown completed (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-02-09 12:39:53,864] INFO [kafka-1-raft-io-thread]: Shutting down (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:39:53,865] INFO [RaftManager id=1] Beginning graceful shutdown (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:39:53,871] INFO [RaftManager id=1] Graceful shutdown completed (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:39:53,871] INFO [kafka-1-raft-io-thread]: Stopped (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:39:53,883] INFO [RaftManager id=1] Completed graceful shutdown of RaftClient (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:39:53,885] INFO [kafka-1-raft-io-thread]: Shutdown completed (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:39:53,935] INFO [kafka-1-raft-outbound-request-thread]: Shutting down (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-02-09 12:39:53,943] INFO [kafka-1-raft-outbound-request-thread]: Stopped (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-02-09 12:39:53,943] INFO [kafka-1-raft-outbound-request-thread]: Shutdown completed (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-02-09 12:39:53,962] INFO [ProducerStateManager partition=__cluster_metadata-0] Wrote producer snapshot at offset 77 with 0 producer ids in 16 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-02-09 12:39:54,022] INFO [ControllerRegistrationManager id=1 incarnation=bP2_u43oQaSwfUoh50O18Q] beginShutdown: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,027] INFO [ControllerRegistrationManager id=1 incarnation=bP2_u43oQaSwfUoh50O18Q] shutting down. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:39:54,027] INFO [controller-1-to-controller-registration-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:54,029] INFO [controller-1-to-controller-registration-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:54,030] INFO [controller-1-to-controller-registration-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:54,039] INFO Node to controller channel manager for registration shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:39:54,040] INFO [ControllerRegistrationManager id=1 incarnation=bP2_u43oQaSwfUoh50O18Q] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,044] INFO [controller-1-to-controller-registration-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:39:54,045] WARN [NodeToControllerChannelManager id=1 name=registration] Attempting to close NetworkClient that has already been closed. (org.apache.kafka.clients.NetworkClient)
[2026-02-09 12:39:54,045] INFO Node to controller channel manager for registration shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:39:54,049] INFO [ControllerRegistrationManager id=1 incarnation=bP2_u43oQaSwfUoh50O18Q] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,059] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2026-02-09 12:39:54,080] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2026-02-09 12:39:54,092] INFO [QuorumController id=1] QuorumController#beginShutdown: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,093] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2026-02-09 12:39:54,163] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2026-02-09 12:39:54,173] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2026-02-09 12:39:54,184] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2026-02-09 12:39:54,189] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:54,196] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:54,197] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:39:54,206] INFO [controller-1-ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,206] INFO [controller-1-ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,213] INFO [controller-1-ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,219] INFO [controller-1-ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,222] INFO [controller-1-ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,222] INFO [controller-1-ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,225] INFO [controller-1-ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,228] INFO [controller-1-ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,229] INFO [controller-1-ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,231] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,231] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,238] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:39:54,238] INFO [QuorumController id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,247] INFO [SharedServer id=1] Stopping SharedServer (kafka.server.SharedServer)
[2026-02-09 12:39:54,263] INFO [MetadataLoader id=1] beginShutdown: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,265] INFO [SnapshotGenerator id=1] close: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,275] INFO [SnapshotGenerator id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,279] INFO [MetadataLoader id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,285] INFO [SnapshotGenerator id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:39:54,307] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2026-02-09 12:39:54,308] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2026-02-09 12:39:54,308] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2026-02-09 12:39:54,309] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:39:54,312] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:40:13,785] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2026-02-09 12:40:14,397] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2026-02-09 12:40:15,207] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2026-02-09 12:40:15,218] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
[2026-02-09 12:40:17,013] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-02-09 12:40:17,175] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2026-02-09 12:40:17,262] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-02-09 12:40:17,277] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
[2026-02-09 12:40:17,586] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:40:17,589] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-02-09 12:40:17,591] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-02-09 12:40:17,865] INFO Initialized snapshots with IDs SortedSet() from /tmp/kraft-combined-logs/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2026-02-09 12:40:17,924] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-02-09 12:40:17,988] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:40:18,009] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=Optional.empty), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/127.0.0.1:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:40:18,015] INFO [RaftManager id=1] Starting request manager with static voters: [localhost:9093 (id: 1 rack: null)] (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:40:18,098] INFO [RaftManager id=1] Attempting durable transition to Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1050, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:40:18,594] INFO [RaftManager id=1] Completed transition to Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1050, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:40:18,608] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=zqsj13dPfURRNV56tYFbBg,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@5136207f}, highWatermark=Optional.empty, electionTimeoutMs=1829) from Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1050, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:40:18,639] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=zqsj13dPfURRNV56tYFbBg,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@5136207f}, highWatermark=Optional.empty, electionTimeoutMs=1829) from Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1050, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:40:18,660] INFO [RaftManager id=1] Attempting durable transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=Optional[zqsj13dPfURRNV56tYFbBg]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=zqsj13dPfURRNV56tYFbBg,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@5136207f}, highWatermark=Optional.empty, electionTimeoutMs=1829) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:40:18,712] INFO [RaftManager id=1] Completed transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=Optional[zqsj13dPfURRNV56tYFbBg]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=zqsj13dPfURRNV56tYFbBg,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@5136207f}, highWatermark=Optional.empty, electionTimeoutMs=1829) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:40:18,845] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-02-09 12:40:18,853] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:40:18,914] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:18,929] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2026-02-09 12:40:18,942] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2026-02-09 12:40:19,023] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,030] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
[2026-02-09 12:40:19,083] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@768644790 (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:40:19,091] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@768644790 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:40:19,115] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,135] INFO [MetadataLoader id=1] initializeNewPublishers: The loader finished catching up to the current high water mark of 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,144] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@16488443 (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:40:19,172] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@16488443 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:40:19,205] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 0 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,242] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:19,245] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:19,259] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:19,286] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:19,422] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:19,490] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,491] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2026-02-09 12:40:19,492] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2026-02-09 12:40:19,493] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2026-02-09 12:40:19,497] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,498] INFO [ControllerServer id=1] Loaded new metadata Features(metadataVersion=3.9-IV0, finalizedFeatures={metadata.version=21}, finalizedFeaturesEpoch=4). (org.apache.kafka.metadata.publisher.FeaturesPublisher)
[2026-02-09 12:40:19,498] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,499] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,503] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,505] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,517] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,520] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,521] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
[2026-02-09 12:40:19,528] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,540] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:19,561] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:19,564] INFO [ControllerRegistrationManager id=1 incarnation=dg7UeuSLRtSA_eXb_VJgPQ] initialized channel manager. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:40:19,568] INFO [ControllerRegistrationManager id=1 incarnation=dg7UeuSLRtSA_eXb_VJgPQ] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=dg7UeuSLRtSA_eXb_VJgPQ, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='localhost', port=9093, securityProtocol=0)], features=[Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)]) (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:40:19,569] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:19,568] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2026-02-09 12:40:19,573] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2026-02-09 12:40:19,577] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2026-02-09 12:40:19,577] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2026-02-09 12:40:19,579] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2026-02-09 12:40:19,582] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
[2026-02-09 12:40:19,730] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:19,752] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:19,813] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:19,816] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:20,160] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-02-09 12:40:20,174] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-02-09 12:40:20,184] INFO [ControllerRegistrationManager id=1 incarnation=dg7UeuSLRtSA_eXb_VJgPQ] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:40:20,206] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:20,219] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:20,250] INFO [ControllerRegistrationManager id=1 incarnation=dg7UeuSLRtSA_eXb_VJgPQ] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:40:20,323] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-02-09 12:40:20,451] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-02-09 12:40:20,471] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2026-02-09 12:40:20,488] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:20,495] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:20,563] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:20,565] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:20,646] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:20,672] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:20,677] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:20,684] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:20,714] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:20,811] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:20,826] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:20,984] INFO Unable to read the broker epoch in /tmp/kraft-combined-logs. (kafka.log.LogManager)
[2026-02-09 12:40:21,024] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:21,061] INFO [BrokerLifecycleManager id=1] Incarnation f1ZUwel_RkSVnC71bMY_1Q of broker 1 in cluster kkIHi7xMQGSUXYFu6OySXw is now STARTING. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:40:21,109] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:21,266] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:21,553] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-02-09 12:40:21,629] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:21,645] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:21,659] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=8, epoch=1) with metadata.version 3.9-IV0. (kafka.server.metadata.BrokerMetadataPublisher)
[2026-02-09 12:40:21,641] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-02-09 12:40:21,702] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-02-09 12:40:21,717] INFO Loading logs from log dirs ArrayBuffer(/tmp/kraft-combined-logs) (kafka.log.LogManager)
[2026-02-09 12:40:21,731] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 9 (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:40:21,749] INFO No logs found to be loaded in /tmp/kraft-combined-logs (kafka.log.LogManager)
[2026-02-09 12:40:21,778] INFO Loaded 0 logs in 60ms (kafka.log.LogManager)
[2026-02-09 12:40:21,784] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2026-02-09 12:40:21,791] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2026-02-09 12:40:21,995] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2026-02-09 12:40:22,141] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-02-09 12:40:22,174] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2026-02-09 12:40:22,180] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:40:22,201] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:40:22,221] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:40:22,243] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:40:22,244] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-02-09 12:40:22,370] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:40:22,380] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:40:22,383] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-02-09 12:40:22,383] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-02-09 12:40:22,384] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-02-09 12:40:22,393] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://localhost:9092,CONTROLLER://localhost:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092,CONTROLLER://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /tmp/kraft-combined-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2026-02-09 12:40:22,414] INFO [BrokerLifecycleManager id=1] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:40:22,480] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-02-09 12:40:22,572] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:40:22,575] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-02-09 12:40:22,578] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-02-09 12:40:22,584] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2026-02-09 12:40:22,585] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2026-02-09 12:40:22,595] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-02-09 12:40:22,595] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-02-09 12:40:22,596] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-02-09 12:40:22,596] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-02-09 12:40:22,596] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2026-02-09 12:40:22,599] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:40:22,601] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:40:22,601] INFO Kafka startTimeMs: 1770637222598 (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:40:22,606] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
[2026-02-09 12:40:23,048] INFO Sent auto-creation request for Set(fuzzy-alerts) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-02-09 12:40:23,253] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:40:23,336] INFO [LogLoader partition=fuzzy-alerts-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:40:23,367] INFO Created log for partition fuzzy-alerts-0 in /tmp/kraft-combined-logs/fuzzy-alerts-0 with properties {} (kafka.log.LogManager)
[2026-02-09 12:40:23,411] INFO [Partition fuzzy-alerts-0 broker=1] No checkpointed highwatermark is found for partition fuzzy-alerts-0 (kafka.cluster.Partition)
[2026-02-09 12:40:23,448] INFO [Partition fuzzy-alerts-0 broker=1] Log loaded for partition fuzzy-alerts-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-02-09 12:40:49,473] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2026-02-09 12:40:49,487] INFO [BrokerServer id=1] Transition from STARTED to SHUTTING_DOWN (kafka.server.BrokerServer)
[2026-02-09 12:40:49,494] INFO [BrokerServer id=1] shutting down (kafka.server.BrokerServer)
[2026-02-09 12:40:49,500] INFO [BrokerLifecycleManager id=1] Beginning controlled shutdown. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:40:49,649] INFO [BrokerLifecycleManager id=1] The broker is in PENDING_CONTROLLED_SHUTDOWN state, still waiting for the active controller. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:40:49,676] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:40:49,677] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(fuzzy-alerts-0) (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:40:49,772] INFO [BrokerLifecycleManager id=1] The controller has asked us to exit controlled shutdown. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:40:49,774] INFO [BrokerLifecycleManager id=1] beginShutdown: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:49,779] INFO [BrokerLifecycleManager id=1] Transitioning from PENDING_CONTROLLED_SHUTDOWN to SHUTTING_DOWN. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:40:49,780] INFO [broker-1-to-controller-heartbeat-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:49,783] INFO [SocketServer listenerType=BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2026-02-09 12:40:49,784] INFO [broker-1-to-controller-heartbeat-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:49,786] INFO [broker-1-to-controller-heartbeat-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:49,831] INFO Node to controller channel manager for heartbeat shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:40:49,872] INFO [SocketServer listenerType=BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2026-02-09 12:40:49,924] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2026-02-09 12:40:49,944] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2026-02-09 12:40:49,954] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:49,960] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:49,966] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:49,996] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2026-02-09 12:40:50,021] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:40:50,028] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2026-02-09 12:40:50,038] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-02-09 12:40:50,077] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-02-09 12:40:50,083] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-02-09 12:40:50,104] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:40:50,105] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:40:50,127] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,149] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,149] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,154] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,156] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,156] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,158] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:40:50,159] INFO [AssignmentsManager id=1]KafkaEventQueue#close: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:50,180] INFO [AssignmentsManager id=1] shutting down. (org.apache.kafka.server.AssignmentsManager)
[2026-02-09 12:40:50,180] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,183] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,186] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,200] INFO Node to controller channel manager for directory-assignments shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:40:50,203] INFO [AssignmentsManager id=1]closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:50,206] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2026-02-09 12:40:50,210] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-02-09 12:40:50,211] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-02-09 12:40:50,211] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-02-09 12:40:50,212] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:40:50,215] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2026-02-09 12:40:50,216] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:40:50,217] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2026-02-09 12:40:50,217] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,217] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,218] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,218] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,219] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,219] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,220] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,220] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,221] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,222] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,224] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,229] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,232] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,237] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,241] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:50,305] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2026-02-09 12:40:50,306] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2026-02-09 12:40:50,307] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2026-02-09 12:40:50,312] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2026-02-09 12:40:50,316] INFO [broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,316] INFO [broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,319] INFO [broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,321] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:40:50,323] INFO [broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,324] INFO [broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,326] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:40:50,326] INFO [broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,333] INFO Shutting down. (kafka.log.LogManager)
[2026-02-09 12:40:50,344] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2026-02-09 12:40:50,350] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2026-02-09 12:40:50,351] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2026-02-09 12:40:50,592] INFO Shutdown complete. (kafka.log.LogManager)
[2026-02-09 12:40:50,601] INFO [broker-1-ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,619] INFO [broker-1-ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,628] INFO [broker-1-ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,631] INFO [broker-1-ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,631] INFO [broker-1-ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,638] INFO [broker-1-ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,638] INFO [broker-1-ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,639] INFO [broker-1-ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,641] INFO [broker-1-ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,641] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,642] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,646] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:50,651] INFO [SocketServer listenerType=BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2026-02-09 12:40:50,727] INFO [SocketServer listenerType=BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2026-02-09 12:40:50,729] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2026-02-09 12:40:50,730] INFO [BrokerLifecycleManager id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:50,731] INFO [client-metrics-reaper]: Shutting down (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-02-09 12:40:50,732] INFO [client-metrics-reaper]: Stopped (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-02-09 12:40:50,734] INFO [client-metrics-reaper]: Shutdown completed (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-02-09 12:40:50,753] INFO [BrokerServer id=1] shut down completed (kafka.server.BrokerServer)
[2026-02-09 12:40:50,754] INFO [BrokerServer id=1] Transition from SHUTTING_DOWN to SHUTDOWN (kafka.server.BrokerServer)
[2026-02-09 12:40:50,755] INFO [ControllerServer id=1] shutting down (kafka.server.ControllerServer)
[2026-02-09 12:40:50,757] INFO [raft-expiration-reaper]: Shutting down (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-02-09 12:40:50,832] INFO [raft-expiration-reaper]: Stopped (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-02-09 12:40:50,833] INFO [raft-expiration-reaper]: Shutdown completed (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-02-09 12:40:50,847] INFO [kafka-1-raft-io-thread]: Shutting down (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:40:50,847] INFO [RaftManager id=1] Beginning graceful shutdown (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:40:50,850] INFO [RaftManager id=1] Graceful shutdown completed (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:40:50,850] INFO [kafka-1-raft-io-thread]: Stopped (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:40:50,851] INFO [RaftManager id=1] Completed graceful shutdown of RaftClient (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:40:50,861] INFO [kafka-1-raft-io-thread]: Shutdown completed (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:40:50,885] INFO [kafka-1-raft-outbound-request-thread]: Shutting down (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-02-09 12:40:50,893] INFO [kafka-1-raft-outbound-request-thread]: Shutdown completed (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-02-09 12:40:50,898] INFO [kafka-1-raft-outbound-request-thread]: Stopped (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-02-09 12:40:50,914] INFO [ProducerStateManager partition=__cluster_metadata-0] Wrote producer snapshot at offset 74 with 0 producer ids in 19 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-02-09 12:40:50,927] INFO [ControllerRegistrationManager id=1 incarnation=dg7UeuSLRtSA_eXb_VJgPQ] beginShutdown: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:50,931] INFO [ControllerRegistrationManager id=1 incarnation=dg7UeuSLRtSA_eXb_VJgPQ] shutting down. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:40:50,932] INFO [controller-1-to-controller-registration-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,933] INFO [controller-1-to-controller-registration-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,933] INFO [controller-1-to-controller-registration-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,947] INFO Node to controller channel manager for registration shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:40:50,947] INFO [ControllerRegistrationManager id=1 incarnation=dg7UeuSLRtSA_eXb_VJgPQ] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:50,954] INFO [controller-1-to-controller-registration-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:40:50,955] WARN [NodeToControllerChannelManager id=1 name=registration] Attempting to close NetworkClient that has already been closed. (org.apache.kafka.clients.NetworkClient)
[2026-02-09 12:40:50,955] INFO Node to controller channel manager for registration shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2026-02-09 12:40:50,957] INFO [ControllerRegistrationManager id=1 incarnation=dg7UeuSLRtSA_eXb_VJgPQ] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:50,959] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2026-02-09 12:40:50,998] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2026-02-09 12:40:51,000] INFO [QuorumController id=1] QuorumController#beginShutdown: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:51,003] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2026-02-09 12:40:51,017] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2026-02-09 12:40:51,023] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2026-02-09 12:40:51,031] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2026-02-09 12:40:51,037] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:51,059] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:51,067] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:40:51,083] INFO [controller-1-ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,086] INFO [controller-1-ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,090] INFO [controller-1-ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,098] INFO [controller-1-ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,101] INFO [controller-1-ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,102] INFO [controller-1-ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,107] INFO [controller-1-ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,108] INFO [controller-1-ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,109] INFO [controller-1-ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,109] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,110] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,110] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:40:51,110] INFO [QuorumController id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:51,152] INFO [SharedServer id=1] Stopping SharedServer (kafka.server.SharedServer)
[2026-02-09 12:40:51,162] INFO [MetadataLoader id=1] beginShutdown: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:51,163] INFO [SnapshotGenerator id=1] close: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:51,173] INFO [SnapshotGenerator id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:51,184] INFO [MetadataLoader id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:51,189] INFO [SnapshotGenerator id=1] closed event queue. (org.apache.kafka.queue.KafkaEventQueue)
[2026-02-09 12:40:51,209] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2026-02-09 12:40:51,219] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2026-02-09 12:40:51,220] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2026-02-09 12:40:51,221] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:40:51,225] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:48:52,990] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2026-02-09 12:48:53,769] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2026-02-09 12:48:54,693] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2026-02-09 12:48:54,749] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
[2026-02-09 12:48:56,702] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-02-09 12:48:56,844] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2026-02-09 12:48:56,934] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-02-09 12:48:56,947] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
[2026-02-09 12:48:57,433] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-02-09 12:48:57,436] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-02-09 12:48:57,437] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-02-09 12:48:57,626] INFO Initialized snapshots with IDs SortedSet() from /tmp/kraft-combined-logs/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2026-02-09 12:48:57,707] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-02-09 12:48:57,796] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:48:57,833] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=Optional.empty), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/127.0.0.1:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:48:57,837] INFO [RaftManager id=1] Starting request manager with static voters: [localhost:9093 (id: 1 rack: null)] (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:48:57,867] INFO [RaftManager id=1] Attempting durable transition to Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1157, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:48:58,661] INFO [RaftManager id=1] Completed transition to Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1157, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:48:58,681] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=xaYrV_6WHKXVpDC0laz_BA,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@5136207f}, highWatermark=Optional.empty, electionTimeoutMs=1227) from Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1157, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:48:58,718] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=xaYrV_6WHKXVpDC0laz_BA,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@5136207f}, highWatermark=Optional.empty, electionTimeoutMs=1227) from Unattached(epoch=0, votedKey=null, voters=[1], electionTimeoutMs=1157, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:48:58,743] INFO [RaftManager id=1] Attempting durable transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=Optional[xaYrV_6WHKXVpDC0laz_BA]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=xaYrV_6WHKXVpDC0laz_BA,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@5136207f}, highWatermark=Optional.empty, electionTimeoutMs=1227) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:48:58,787] INFO [RaftManager id=1] Completed transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=Optional[xaYrV_6WHKXVpDC0laz_BA]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=xaYrV_6WHKXVpDC0laz_BA,epoch=1, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@5136207f}, highWatermark=Optional.empty, electionTimeoutMs=1227) (org.apache.kafka.raft.QuorumState)
[2026-02-09 12:48:58,920] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-02-09 12:48:58,921] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-02-09 12:48:59,084] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,099] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2026-02-09 12:48:59,106] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2026-02-09 12:48:59,162] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
[2026-02-09 12:48:59,221] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,291] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@768644790 (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:48:59,306] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@768644790 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:48:59,342] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,354] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,446] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@16488443 (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:48:59,446] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@16488443 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2026-02-09 12:48:59,464] INFO [MetadataLoader id=1] initializeNewPublishers: The loader finished catching up to the current high water mark of 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,581] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 0 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,582] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:48:59,617] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:48:59,635] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:48:59,659] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:48:59,819] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:48:59,870] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,872] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2026-02-09 12:48:59,874] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2026-02-09 12:48:59,876] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,883] INFO [ControllerServer id=1] Loaded new metadata Features(metadataVersion=3.9-IV0, finalizedFeatures={metadata.version=21}, finalizedFeaturesEpoch=4). (org.apache.kafka.metadata.publisher.FeaturesPublisher)
[2026-02-09 12:48:59,884] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,884] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,893] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2026-02-09 12:48:59,919] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,960] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,983] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,985] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,989] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:48:59,986] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
[2026-02-09 12:48:59,992] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 4 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:49:00,017] INFO [ControllerRegistrationManager id=1 incarnation=iGmHHz5zSxm3ca1one32_A] initialized channel manager. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:49:00,021] INFO [ControllerRegistrationManager id=1 incarnation=iGmHHz5zSxm3ca1one32_A] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=iGmHHz5zSxm3ca1one32_A, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='localhost', port=9093, securityProtocol=0)], features=[Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)]) (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:49:00,022] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2026-02-09 12:49:00,023] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2026-02-09 12:49:00,023] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2026-02-09 12:49:00,023] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2026-02-09 12:49:00,024] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2026-02-09 12:49:00,029] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
[2026-02-09 12:49:00,022] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:00,032] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:00,055] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:49:00,098] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:49:00,110] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:49:00,110] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-02-09 12:49:00,392] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-02-09 12:49:00,399] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-02-09 12:49:00,407] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:00,409] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:00,440] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-02-09 12:49:00,788] INFO [ControllerRegistrationManager id=1 incarnation=iGmHHz5zSxm3ca1one32_A] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:49:00,803] INFO [ControllerRegistrationManager id=1 incarnation=iGmHHz5zSxm3ca1one32_A] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
[2026-02-09 12:49:00,831] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-02-09 12:49:00,843] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2026-02-09 12:49:00,943] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:00,947] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:00,991] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:00,992] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:01,083] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:49:01,090] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:49:01,099] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:49:01,104] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:49:01,106] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:49:01,188] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:49:01,194] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:49:01,303] INFO Unable to read the broker epoch in /tmp/kraft-combined-logs. (kafka.log.LogManager)
[2026-02-09 12:49:01,330] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:01,332] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-02-09 12:49:01,438] INFO [BrokerLifecycleManager id=1] Incarnation FedjpYnlTBOTTq3DxyYoKQ of broker 1 in cluster ArGis9DRSfC8-4ZfUt7_7g is now STARTING. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:49:01,546] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-02-09 12:49:01,743] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:49:01,743] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:49:01,744] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=8, epoch=1) with metadata.version 3.9-IV0. (kafka.server.metadata.BrokerMetadataPublisher)
[2026-02-09 12:49:01,746] INFO Loading logs from log dirs ArrayBuffer(/tmp/kraft-combined-logs) (kafka.log.LogManager)
[2026-02-09 12:49:01,753] INFO No logs found to be loaded in /tmp/kraft-combined-logs (kafka.log.LogManager)
[2026-02-09 12:49:01,769] INFO Loaded 0 logs in 20ms (kafka.log.LogManager)
[2026-02-09 12:49:01,769] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2026-02-09 12:49:01,778] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-02-09 12:49:01,785] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-02-09 12:49:01,791] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-02-09 12:49:01,845] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2026-02-09 12:49:01,867] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 9 (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:49:02,591] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2026-02-09 12:49:02,671] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-02-09 12:49:02,676] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2026-02-09 12:49:02,700] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:49:02,729] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2026-02-09 12:49:02,743] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:49:02,768] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-02-09 12:49:02,770] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-02-09 12:49:02,841] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
[2026-02-09 12:49:02,894] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:49:02,896] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-02-09 12:49:02,897] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-02-09 12:49:02,898] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-02-09 12:49:02,901] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://localhost:9092,CONTROLLER://localhost:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092,CONTROLLER://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /tmp/kraft-combined-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2026-02-09 12:49:02,965] INFO [BrokerLifecycleManager id=1] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:49:02,970] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-02-09 12:49:03,055] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2026-02-09 12:49:03,056] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-02-09 12:49:03,060] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-02-09 12:49:03,062] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2026-02-09 12:49:03,067] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2026-02-09 12:49:03,073] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-02-09 12:49:03,075] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-02-09 12:49:03,076] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-02-09 12:49:03,076] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-02-09 12:49:03,076] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2026-02-09 12:49:03,077] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:49:03,077] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:49:03,077] INFO Kafka startTimeMs: 1770637743076 (org.apache.kafka.common.utils.AppInfoParser)
[2026-02-09 12:49:03,083] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
[2026-02-09 12:59:03,948] INFO [NodeToControllerChannelManager id=1 name=registration] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
